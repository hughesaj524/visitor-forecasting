{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from operator import xor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ml_metrics import rmsle\n",
    "%matplotlib inline\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "\n",
    "air = {\n",
    "    \"reserve\": pd.read_csv(\"data/air/air_reserve.csv\", parse_dates=[\"visit_datetime\", \"reserve_datetime\"]),\n",
    "    \"store_info\": pd.read_csv(\"data/air/air_store_info.csv\"),\n",
    "    \"visit_data\": pd.read_csv(\"data/air/air_visit_data.csv\", parse_dates=[\"visit_date\"])\n",
    "}\n",
    "\n",
    "hpg = {\n",
    "    \"reserve\": pd.read_csv(\"data/hpg/hpg_reserve.csv\", parse_dates=[\"visit_datetime\", \"reserve_datetime\"]),\n",
    "    \"store_info\": pd.read_csv(\"data/hpg/hpg_store_info.csv\")\n",
    "}\n",
    "\n",
    "date_info = pd.read_csv(\"data/date_info.csv\", parse_dates=[\"calendar_date\"])\n",
    "store_id_relation = pd.read_csv(\"data/store_id_relation.csv\")\n",
    "\n",
    "def remove_outliers(data):\n",
    "    df_0 = data.loc[data.visitors == 0]   \n",
    "    q1 = np.percentile(data.visitors, 25, axis=0)\n",
    "    q3 = np.percentile(data.visitors, 75, axis=0)\n",
    "    k = 2.8\n",
    "    iqr = q3 - q1\n",
    "    df_temp = data.loc[data.visitors > q1 - k*iqr]\n",
    "    df_temp = data.loc[data.visitors < q3 + k*iqr]\n",
    "    frames = [df_0, df_temp]\n",
    "    result = pd.concat(frames)\n",
    "    return result\n",
    "\n",
    "air[\"visit_data\"] = remove_outliers(air[\"visit_data\"])\n",
    "\n",
    "df_test = pd.read_csv('sample_submission.csv')\n",
    "df_test['air_store_id'] = df_test['id'].apply(lambda x: '_'.join(x.split('_')[:2]))\n",
    "df_test['visit_date'] = df_test['id'].apply(lambda x: x.split('_')[-1])\n",
    "index_test = df_test['id']\n",
    "del df_test['id'], df_test['visitors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping and dropping useless information in df_hr ...\n",
      "mapping and dropping useless information in df_hr Done!\n",
      "-----------------------------------------------------------------------------------------\n",
      "mapping and dropping useless information in df_hr ...\n",
      "mapping and dropping useless information in df_hs Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('mapping and dropping useless information in df_hr ...')\n",
    "s_1 = store_id_relation['air_store_id']\n",
    "s_2 = store_id_relation['hpg_store_id']\n",
    "a_h_map = dict(zip(s_2.values, s_1.values))\n",
    "del s_1, s_2\n",
    "\n",
    "hpg[\"reserve\"]['air_store_id'] = hpg[\"reserve\"]['hpg_store_id'].map(a_h_map)\n",
    "hpg[\"reserve\"] = hpg[\"reserve\"].drop('hpg_store_id', axis=1).dropna()\n",
    "\n",
    "\n",
    "print('mapping and dropping useless information in df_hr Done!')\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "\n",
    "print('mapping and dropping useless information in df_hr ...')\n",
    "\n",
    "hpg[\"store_info\"]['air_store_id'] = hpg[\"store_info\"]['hpg_store_id'].map(a_h_map)\n",
    "hpg[\"store_info\"] = hpg[\"store_info\"].drop('hpg_store_id', axis=1).dropna()\n",
    "print('mapping and dropping useless information in df_hs Done!')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Looking for correlations in data:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "air[\"visit_data\"][\"num_of_week\"] = air[\"visit_data\"][\"visit_date\"].dt.dayofweek\n",
    "\n",
    "corr_table = air[\"visit_data\"]\n",
    "corr_table[\"visitors\"] = corr_table[\"visitors\"].map(np.log1p)\n",
    "corr_table = pd.merge(corr_table, air[\"store_info\"], on=\"air_store_id\")\n",
    "corr_table = pd.merge(corr_table, date_info,\n",
    "                      left_on=\"visit_date\", right_on=\"calendar_date\")\n",
    "corr_table[\"air_area_name\"] = corr_table[\"air_area_name\"].str.partition(\" \")\n",
    "corr_table[\"weekend_flg\"] = corr_table[\"num_of_week\"].map(lambda n: 1 if n in (1,2) else 0)\n",
    "corr_table[\"not_workday_flg\"] = corr_table[\"holiday_flg\"].combine(corr_table[\"weekend_flg\"], xor)\n",
    "corr_table = corr_table.drop(columns=[\"day_of_week\", \"visit_date\"])\n",
    "print(corr_table.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(corr_table.corr())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "corr_table[\"cumul_vis\"] = corr_table[\"visitors\"].cummax()\n",
    "corr_table.loc[:,[\"calendar_date\", \"cumul_vis\", \"visitors\"]].plot.line(x=\"calendar_date\", subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "label encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(air[\"store_info\"]['air_genre_name'])\n",
    "air[\"store_info\"]['air_genre_name'] = le.fit_transform(air[\"store_info\"]['air_genre_name'])\n",
    "\n",
    "le.fit(air[\"store_info\"]['air_area_name'])\n",
    "air[\"store_info\"]['air_area_name'] = le.fit_transform(air[\"store_info\"]['air_area_name'])\n",
    "\n",
    "le.fit(hpg[\"store_info\"]['hpg_genre_name'])\n",
    "hpg[\"store_info\"]['hpg_genre_name'] = le.fit_transform(hpg[\"store_info\"]['hpg_genre_name'])\n",
    "\n",
    "le.fit(hpg[\"store_info\"]['hpg_area_name'])\n",
    "hpg[\"store_info\"]['hpg_area_name'] = le.fit_transform(hpg[\"store_info\"]['hpg_area_name'])\n",
    "\n",
    "\n",
    "\n",
    "le.fit(air[\"store_info\"]['air_store_id'])\n",
    "\n",
    "\n",
    "air[\"reserve\"]['air_store_id'] = le.transform(air[\"reserve\"]['air_store_id'])\n",
    "air[\"store_info\"]['air_store_id'] = le.transform(air[\"store_info\"]['air_store_id'])\n",
    "air[\"visit_data\"]['air_store_id'] = le.transform(air[\"visit_data\"]['air_store_id'])\n",
    "hpg[\"reserve\"]['air_store_id'] = le.transform(hpg[\"reserve\"]['air_store_id'])\n",
    "hpg[\"store_info\"]['air_store_id'] = le.transform(hpg[\"store_info\"]['air_store_id'])\n",
    "\n",
    "df_test['air_store_id'] = le.transform(df_test['air_store_id'])\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seperating date time features done! ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "def seperate_date(data):\n",
    "    # split date feature in reservation datetime\n",
    "    data_time = pd.to_datetime(data.reserve_datetime, format=time_format)\n",
    "    data['Year_re']= data_time.dt.year\n",
    "    data['Month_re'] = data_time.dt.month\n",
    "    data['DayOfYear_re'] = data_time.dt.dayofyear\n",
    "    data['DayOfWeek_re'] = data_time.dt.dayofweek\n",
    "    data['Hour_re'] = data_time.dt.hour\n",
    "    return data\n",
    "\n",
    "seperate_date(air[\"reserve\"])\n",
    "\n",
    "\n",
    "def seperate_date(data):\n",
    "    # split date feature in reservation datetime\n",
    "    data_time = pd.to_datetime(data.reserve_datetime, format=time_format)\n",
    "    data['Year_re_h']= data_time.dt.year\n",
    "    data['Month_re_h'] = data_time.dt.month\n",
    "    data['DayOfYear_re_h'] = data_time.dt.dayofyear\n",
    "    data['DayOfWeek_re_h'] = data_time.dt.dayofweek\n",
    "    data['Hour_re_h'] = data_time.dt.hour\n",
    "    return data\n",
    "\n",
    "seperate_date(hpg[\"reserve\"])\n",
    "\n",
    "\n",
    "time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "def seperate_date(data):\n",
    "    # split date feature in reserved visiting datetime\n",
    "    data_time = pd.to_datetime(data.visit_datetime, format=time_format)\n",
    "    data['Year_re_visit']= data_time.dt.year\n",
    "    data['Month_re_visit'] = data_time.dt.month\n",
    "    data['DayOfYear_re_visit'] = data_time.dt.dayofyear\n",
    "    data['DayOfWeek_re_visit'] = data_time.dt.dayofweek\n",
    "    data['Hour_re_visit'] = data_time.dt.hour\n",
    "    return data\n",
    "\n",
    "seperate_date(air[\"reserve\"])\n",
    "\n",
    "\n",
    "def seperate_date(data):\n",
    "    # split date feature in reserved visiting datetime\n",
    "    data_time = pd.to_datetime(data.visit_datetime, format=time_format)\n",
    "    data['Year_re_visit_h']= data_time.dt.year\n",
    "    data['Month_re_visit_h'] = data_time.dt.month\n",
    "    data['DayOfYear_re_visit_h'] = data_time.dt.dayofyear\n",
    "    data['WeekOfYear_re_visit_h'] = data_time.dt.week\n",
    "    data['DayOfWeek_re_visit_h'] = data_time.dt.dayofweek\n",
    "    data['Hour_re_visit_h'] = data_time.dt.hour\n",
    "    return data\n",
    "\n",
    "seperate_date(hpg[\"reserve\"])\n",
    "\n",
    "print('seperating date time features done! ...')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging dataframes ...\n",
      "merging dataframes done!\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "features_to_drop = [\n",
    "        'air_store_id__'\n",
    "        ]\n",
    "\n",
    "def merge_df(data, data_to_join):\n",
    "    # merge dataframes        \n",
    "    data = data.join(data_to_join, on='air_store_id', rsuffix='__', how='left')   \n",
    "    return data\n",
    "\n",
    "def fix_data(data):\n",
    "    # drop __ data    \n",
    "    for feature in features_to_drop:\n",
    "        data.drop(feature, axis=1)\n",
    "    return data\n",
    "\n",
    "# Merge to df_train\n",
    "print('merging dataframes ...')\n",
    "df_train = merge_df(air[\"visit_data\"], air[\"reserve\"])\n",
    "df_train = merge_df(df_train, air[\"store_info\"])\n",
    "\n",
    "hpg[\"reserve\"]['reserve_visitors_hr'] = hpg[\"reserve\"]['reserve_visitors'] \n",
    "hpg[\"reserve\"].drop('reserve_visitors', axis=1) \n",
    "\n",
    "hpg[\"store_info\"]['latitude_hr'] = hpg[\"store_info\"]['latitude'] \n",
    "hpg[\"store_info\"].drop('latitude', axis=1)\n",
    "\n",
    "hpg[\"store_info\"]['longitude_hr'] = hpg[\"store_info\"]['longitude'] \n",
    "hpg[\"store_info\"].drop('longitude', axis=1) \n",
    "\n",
    "df_train = merge_df(df_train, hpg[\"store_info\"])\n",
    "df_train = merge_df(df_train, hpg[\"store_info\"])\n",
    "gc.collect()\n",
    "fix_data(df_train)\n",
    "\n",
    "# Merge to df_test\n",
    "\n",
    "df_test = merge_df(df_test, air[\"reserve\"])\n",
    "df_test = merge_df(df_test, air[\"store_info\"])\n",
    "\n",
    "df_test = merge_df(df_test, hpg[\"store_info\"])\n",
    "df_test = merge_df(df_test, hpg[\"reserve\"])\n",
    "gc.collect()\n",
    "fix_data(df_test)\n",
    "\n",
    "\n",
    "print('merging dataframes done!')\n",
    "gc.collect()\n",
    "print(\"=========================================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop date-time-hour info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_datetime_info(data):\n",
    "    data = data.drop(['visit_date', 'visit_datetime', 'reserve_datetime', 'visit_datetime__', 'reserve_datetime__'], axis=1)\n",
    "    return data\n",
    "df_train = drop_datetime_info(df_train)\n",
    "df_test = drop_datetime_info(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_train.fillna(-1)\n",
    "test = df_test.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train = shuffle(train, random_state=524)\n",
    "\n",
    "X_pretrain, X_prevalid = train_test_split(train, test_size=0.05, random_state=1224, shuffle=False)\n",
    "\n",
    "X_train = X_pretrain.drop(['visitors'], axis=1)\n",
    "y_train = np.log1p(X_pretrain[\"visitors\"].values)\n",
    "\n",
    "X_valid = X_prevalid.drop(['visitors'], axis=1)\n",
    "y_valid = np.log1p(X_prevalid['visitors'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking mean rmse"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mrmse = pd.DataFrame({\"id\": index_test, \"visitors\": pd.Series([train[\"visitors\"].mean()]*index_test.size)})\n",
    "mrmse.to_csv(\"MRMSE_sub.csv\", index=False) #0.88\n",
    "print(\"MRMSE written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test run without CV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"Training LGBM model...\")\n",
    "params = {\n",
    "    \"application\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"num_leaves\": 32,\n",
    "    \"min_sum_hessian_in_leaf\": 1e-2,\n",
    "    \"min_gain_to_split\": 0,\n",
    "\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"num_threads\": 4,\n",
    "    \"metric\": \"rmse\"\n",
    "}\n",
    "\n",
    "d_train = lgb.Dataset(X_train, y_train)\n",
    "d_valid = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "watchlist = [d_train, d_valid]\n",
    "\n",
    "lgb_model1 = lgb.train(params, train_set=d_train, num_boost_round=35000, valid_sets=watchlist, verbose_eval=1000)\n",
    "\n",
    "print(\"Model trained. Predicting...\")\n",
    "\n",
    "test_probs = lgb_model1.predict(test)\n",
    "test_probs = np.expm1(test_probs)\n",
    "\n",
    "result = pd.DataFrame({\"id\": index_test, \"visitors\": test_probs})\n",
    "result.to_csv(\"LGB_sub.csv\", index=False) # 0.60\n",
    "print(\"Prediction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LGBM model with cross-validation...\n",
      "[100]\ttraining's rmse: 0.791755\tvalid_1's rmse: 0.783862\n",
      "[200]\ttraining's rmse: 0.784701\tvalid_1's rmse: 0.776878\n",
      "[300]\ttraining's rmse: 0.778103\tvalid_1's rmse: 0.770322\n",
      "[400]\ttraining's rmse: 0.772073\tvalid_1's rmse: 0.764378\n",
      "[500]\ttraining's rmse: 0.766316\tvalid_1's rmse: 0.758666\n",
      "[600]\ttraining's rmse: 0.760942\tvalid_1's rmse: 0.753373\n",
      "[700]\ttraining's rmse: 0.755944\tvalid_1's rmse: 0.748463\n",
      "[800]\ttraining's rmse: 0.750981\tvalid_1's rmse: 0.743616\n",
      "[900]\ttraining's rmse: 0.746306\tvalid_1's rmse: 0.738996\n",
      "[1000]\ttraining's rmse: 0.741833\tvalid_1's rmse: 0.734585\n",
      "[1100]\ttraining's rmse: 0.737489\tvalid_1's rmse: 0.730306\n",
      "[1200]\ttraining's rmse: 0.73338\tvalid_1's rmse: 0.72616\n",
      "[1300]\ttraining's rmse: 0.729542\tvalid_1's rmse: 0.722319\n",
      "[1400]\ttraining's rmse: 0.725863\tvalid_1's rmse: 0.71868\n",
      "[1500]\ttraining's rmse: 0.722139\tvalid_1's rmse: 0.715002\n",
      "[1600]\ttraining's rmse: 0.718587\tvalid_1's rmse: 0.71147\n",
      "[1700]\ttraining's rmse: 0.715217\tvalid_1's rmse: 0.708118\n",
      "[1800]\ttraining's rmse: 0.712052\tvalid_1's rmse: 0.704985\n",
      "[1900]\ttraining's rmse: 0.708996\tvalid_1's rmse: 0.701977\n",
      "[2000]\ttraining's rmse: 0.706099\tvalid_1's rmse: 0.699121\n",
      "[2100]\ttraining's rmse: 0.703203\tvalid_1's rmse: 0.696303\n",
      "[2200]\ttraining's rmse: 0.700543\tvalid_1's rmse: 0.693662\n",
      "[2300]\ttraining's rmse: 0.69807\tvalid_1's rmse: 0.691203\n",
      "[2400]\ttraining's rmse: 0.695715\tvalid_1's rmse: 0.688857\n",
      "[2500]\ttraining's rmse: 0.693333\tvalid_1's rmse: 0.686529\n",
      "[2600]\ttraining's rmse: 0.69095\tvalid_1's rmse: 0.68418\n",
      "[2700]\ttraining's rmse: 0.688605\tvalid_1's rmse: 0.68186\n",
      "[2800]\ttraining's rmse: 0.68638\tvalid_1's rmse: 0.679695\n",
      "[2900]\ttraining's rmse: 0.684229\tvalid_1's rmse: 0.677589\n",
      "[3000]\ttraining's rmse: 0.682136\tvalid_1's rmse: 0.675538\n",
      "[3100]\ttraining's rmse: 0.680087\tvalid_1's rmse: 0.673502\n",
      "[3200]\ttraining's rmse: 0.678168\tvalid_1's rmse: 0.671594\n",
      "[3300]\ttraining's rmse: 0.676328\tvalid_1's rmse: 0.669758\n",
      "[3400]\ttraining's rmse: 0.674524\tvalid_1's rmse: 0.667983\n",
      "[3500]\ttraining's rmse: 0.672747\tvalid_1's rmse: 0.666228\n",
      "[3600]\ttraining's rmse: 0.671054\tvalid_1's rmse: 0.664566\n",
      "[3700]\ttraining's rmse: 0.669328\tvalid_1's rmse: 0.662874\n",
      "[3800]\ttraining's rmse: 0.667691\tvalid_1's rmse: 0.661288\n",
      "[3900]\ttraining's rmse: 0.666137\tvalid_1's rmse: 0.659777\n",
      "[4000]\ttraining's rmse: 0.664607\tvalid_1's rmse: 0.658298\n",
      "[4100]\ttraining's rmse: 0.663147\tvalid_1's rmse: 0.656874\n",
      "[4200]\ttraining's rmse: 0.661745\tvalid_1's rmse: 0.655522\n",
      "[4300]\ttraining's rmse: 0.660399\tvalid_1's rmse: 0.654226\n",
      "[4400]\ttraining's rmse: 0.659042\tvalid_1's rmse: 0.652917\n",
      "[4500]\ttraining's rmse: 0.657686\tvalid_1's rmse: 0.651608\n",
      "[4600]\ttraining's rmse: 0.656415\tvalid_1's rmse: 0.650365\n",
      "[4700]\ttraining's rmse: 0.655263\tvalid_1's rmse: 0.649229\n",
      "[4800]\ttraining's rmse: 0.654113\tvalid_1's rmse: 0.648119\n",
      "[4900]\ttraining's rmse: 0.652965\tvalid_1's rmse: 0.647035\n",
      "[5000]\ttraining's rmse: 0.651805\tvalid_1's rmse: 0.645935\n",
      "[5100]\ttraining's rmse: 0.650732\tvalid_1's rmse: 0.644915\n",
      "[5200]\ttraining's rmse: 0.649614\tvalid_1's rmse: 0.643826\n",
      "[5300]\ttraining's rmse: 0.648558\tvalid_1's rmse: 0.642816\n",
      "[5400]\ttraining's rmse: 0.647521\tvalid_1's rmse: 0.641824\n",
      "[5500]\ttraining's rmse: 0.646503\tvalid_1's rmse: 0.640866\n",
      "[5600]\ttraining's rmse: 0.645509\tvalid_1's rmse: 0.639929\n",
      "[5700]\ttraining's rmse: 0.644504\tvalid_1's rmse: 0.638981\n",
      "[5800]\ttraining's rmse: 0.64353\tvalid_1's rmse: 0.638071\n",
      "[5900]\ttraining's rmse: 0.642566\tvalid_1's rmse: 0.637169\n",
      "[6000]\ttraining's rmse: 0.64159\tvalid_1's rmse: 0.636245\n",
      "[6100]\ttraining's rmse: 0.640694\tvalid_1's rmse: 0.635397\n",
      "[6200]\ttraining's rmse: 0.639745\tvalid_1's rmse: 0.634506\n",
      "[6300]\ttraining's rmse: 0.63881\tvalid_1's rmse: 0.6336\n",
      "[6400]\ttraining's rmse: 0.637937\tvalid_1's rmse: 0.632768\n",
      "[6500]\ttraining's rmse: 0.637099\tvalid_1's rmse: 0.631967\n",
      "[6600]\ttraining's rmse: 0.636308\tvalid_1's rmse: 0.631198\n",
      "[6700]\ttraining's rmse: 0.635508\tvalid_1's rmse: 0.63043\n",
      "[6800]\ttraining's rmse: 0.634688\tvalid_1's rmse: 0.629635\n",
      "[6900]\ttraining's rmse: 0.633933\tvalid_1's rmse: 0.628913\n",
      "[7000]\ttraining's rmse: 0.633188\tvalid_1's rmse: 0.6282\n",
      "[7100]\ttraining's rmse: 0.632449\tvalid_1's rmse: 0.627487\n",
      "[7200]\ttraining's rmse: 0.631748\tvalid_1's rmse: 0.62682\n",
      "[7300]\ttraining's rmse: 0.631084\tvalid_1's rmse: 0.626183\n",
      "[7400]\ttraining's rmse: 0.63036\tvalid_1's rmse: 0.62549\n",
      "[7500]\ttraining's rmse: 0.629679\tvalid_1's rmse: 0.624836\n",
      "[7600]\ttraining's rmse: 0.629009\tvalid_1's rmse: 0.624198\n",
      "[7700]\ttraining's rmse: 0.628306\tvalid_1's rmse: 0.623532\n",
      "[7800]\ttraining's rmse: 0.62764\tvalid_1's rmse: 0.622906\n",
      "[7900]\ttraining's rmse: 0.626982\tvalid_1's rmse: 0.622283\n",
      "[8000]\ttraining's rmse: 0.626348\tvalid_1's rmse: 0.621683\n",
      "[8100]\ttraining's rmse: 0.625754\tvalid_1's rmse: 0.621117\n",
      "[8200]\ttraining's rmse: 0.625188\tvalid_1's rmse: 0.620587\n",
      "[8300]\ttraining's rmse: 0.624619\tvalid_1's rmse: 0.620057\n",
      "[8400]\ttraining's rmse: 0.624113\tvalid_1's rmse: 0.619589\n",
      "[8500]\ttraining's rmse: 0.623561\tvalid_1's rmse: 0.619068\n",
      "[8600]\ttraining's rmse: 0.62304\tvalid_1's rmse: 0.618585\n",
      "[8700]\ttraining's rmse: 0.622496\tvalid_1's rmse: 0.618088\n",
      "[8800]\ttraining's rmse: 0.621969\tvalid_1's rmse: 0.617603\n",
      "[8900]\ttraining's rmse: 0.621443\tvalid_1's rmse: 0.617117\n",
      "[9000]\ttraining's rmse: 0.620974\tvalid_1's rmse: 0.616687\n",
      "[9100]\ttraining's rmse: 0.620393\tvalid_1's rmse: 0.616146\n",
      "[9200]\ttraining's rmse: 0.619899\tvalid_1's rmse: 0.615688\n",
      "[9300]\ttraining's rmse: 0.619464\tvalid_1's rmse: 0.61529\n",
      "[9400]\ttraining's rmse: 0.619023\tvalid_1's rmse: 0.614874\n",
      "[9500]\ttraining's rmse: 0.618569\tvalid_1's rmse: 0.614452\n",
      "[9600]\ttraining's rmse: 0.61811\tvalid_1's rmse: 0.614024\n",
      "[9700]\ttraining's rmse: 0.617707\tvalid_1's rmse: 0.613653\n",
      "[9800]\ttraining's rmse: 0.617268\tvalid_1's rmse: 0.613249\n",
      "[9900]\ttraining's rmse: 0.616852\tvalid_1's rmse: 0.612866\n",
      "[10000]\ttraining's rmse: 0.61642\tvalid_1's rmse: 0.612475\n",
      "[10100]\ttraining's rmse: 0.615983\tvalid_1's rmse: 0.612073\n",
      "[10200]\ttraining's rmse: 0.615548\tvalid_1's rmse: 0.611675\n",
      "[10300]\ttraining's rmse: 0.61509\tvalid_1's rmse: 0.611258\n",
      "[10400]\ttraining's rmse: 0.614633\tvalid_1's rmse: 0.61084\n",
      "[10500]\ttraining's rmse: 0.614189\tvalid_1's rmse: 0.610436\n",
      "[10600]\ttraining's rmse: 0.613792\tvalid_1's rmse: 0.610071\n",
      "[10700]\ttraining's rmse: 0.613419\tvalid_1's rmse: 0.609729\n",
      "[10800]\ttraining's rmse: 0.613084\tvalid_1's rmse: 0.609422\n",
      "[10900]\ttraining's rmse: 0.612753\tvalid_1's rmse: 0.609118\n",
      "[11000]\ttraining's rmse: 0.612416\tvalid_1's rmse: 0.608808\n",
      "[11100]\ttraining's rmse: 0.612066\tvalid_1's rmse: 0.60848\n",
      "[11200]\ttraining's rmse: 0.611723\tvalid_1's rmse: 0.608167\n",
      "[11300]\ttraining's rmse: 0.611361\tvalid_1's rmse: 0.607831\n",
      "[11400]\ttraining's rmse: 0.611027\tvalid_1's rmse: 0.607523\n",
      "[11500]\ttraining's rmse: 0.610675\tvalid_1's rmse: 0.607197\n",
      "[11600]\ttraining's rmse: 0.610366\tvalid_1's rmse: 0.606921\n",
      "[11700]\ttraining's rmse: 0.610055\tvalid_1's rmse: 0.606637\n",
      "[11800]\ttraining's rmse: 0.609739\tvalid_1's rmse: 0.60635\n",
      "[11900]\ttraining's rmse: 0.609421\tvalid_1's rmse: 0.606059\n",
      "[12000]\ttraining's rmse: 0.609094\tvalid_1's rmse: 0.60577\n",
      "[12100]\ttraining's rmse: 0.608821\tvalid_1's rmse: 0.605526\n",
      "[12200]\ttraining's rmse: 0.60851\tvalid_1's rmse: 0.605258\n",
      "[12300]\ttraining's rmse: 0.608221\tvalid_1's rmse: 0.605009\n",
      "[12400]\ttraining's rmse: 0.607896\tvalid_1's rmse: 0.604715\n",
      "[12500]\ttraining's rmse: 0.607584\tvalid_1's rmse: 0.604437\n",
      "[12600]\ttraining's rmse: 0.607294\tvalid_1's rmse: 0.604182\n",
      "[12700]\ttraining's rmse: 0.606996\tvalid_1's rmse: 0.603919\n",
      "[12800]\ttraining's rmse: 0.606733\tvalid_1's rmse: 0.603692\n",
      "[12900]\ttraining's rmse: 0.606479\tvalid_1's rmse: 0.603475\n",
      "[13000]\ttraining's rmse: 0.60624\tvalid_1's rmse: 0.603276\n",
      "[13100]\ttraining's rmse: 0.606\tvalid_1's rmse: 0.603073\n",
      "[13200]\ttraining's rmse: 0.605785\tvalid_1's rmse: 0.602896\n",
      "[13300]\ttraining's rmse: 0.605563\tvalid_1's rmse: 0.602706\n",
      "[13400]\ttraining's rmse: 0.605336\tvalid_1's rmse: 0.602517\n",
      "[13500]\ttraining's rmse: 0.605123\tvalid_1's rmse: 0.602342\n",
      "[13600]\ttraining's rmse: 0.604929\tvalid_1's rmse: 0.602177\n",
      "[13700]\ttraining's rmse: 0.604727\tvalid_1's rmse: 0.602005\n",
      "[13800]\ttraining's rmse: 0.604535\tvalid_1's rmse: 0.601843\n",
      "[13900]\ttraining's rmse: 0.604326\tvalid_1's rmse: 0.601647\n",
      "[14000]\ttraining's rmse: 0.604129\tvalid_1's rmse: 0.601476\n",
      "[14100]\ttraining's rmse: 0.603932\tvalid_1's rmse: 0.6013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14200]\ttraining's rmse: 0.603749\tvalid_1's rmse: 0.601135\n",
      "[14300]\ttraining's rmse: 0.603554\tvalid_1's rmse: 0.60096\n",
      "[14400]\ttraining's rmse: 0.603369\tvalid_1's rmse: 0.600796\n",
      "[14500]\ttraining's rmse: 0.603186\tvalid_1's rmse: 0.600629\n",
      "[14600]\ttraining's rmse: 0.60301\tvalid_1's rmse: 0.600461\n",
      "[14700]\ttraining's rmse: 0.602822\tvalid_1's rmse: 0.600285\n",
      "[14800]\ttraining's rmse: 0.602636\tvalid_1's rmse: 0.600111\n",
      "[14900]\ttraining's rmse: 0.60246\tvalid_1's rmse: 0.599942\n",
      "[15000]\ttraining's rmse: 0.602293\tvalid_1's rmse: 0.599785\n",
      "[15100]\ttraining's rmse: 0.602128\tvalid_1's rmse: 0.599637\n",
      "[15200]\ttraining's rmse: 0.601975\tvalid_1's rmse: 0.599499\n",
      "[15300]\ttraining's rmse: 0.601825\tvalid_1's rmse: 0.59936\n",
      "[15400]\ttraining's rmse: 0.601657\tvalid_1's rmse: 0.599205\n",
      "[15500]\ttraining's rmse: 0.601512\tvalid_1's rmse: 0.599073\n",
      "[15600]\ttraining's rmse: 0.601357\tvalid_1's rmse: 0.598936\n",
      "[15700]\ttraining's rmse: 0.601206\tvalid_1's rmse: 0.598803\n",
      "[15800]\ttraining's rmse: 0.60107\tvalid_1's rmse: 0.598679\n",
      "[15900]\ttraining's rmse: 0.600929\tvalid_1's rmse: 0.598552\n",
      "[16000]\ttraining's rmse: 0.600787\tvalid_1's rmse: 0.59842\n",
      "[16100]\ttraining's rmse: 0.600655\tvalid_1's rmse: 0.598304\n",
      "[16200]\ttraining's rmse: 0.600531\tvalid_1's rmse: 0.598196\n",
      "[16300]\ttraining's rmse: 0.600411\tvalid_1's rmse: 0.598097\n",
      "[16400]\ttraining's rmse: 0.600279\tvalid_1's rmse: 0.597977\n",
      "[16500]\ttraining's rmse: 0.600162\tvalid_1's rmse: 0.597873\n",
      "[16600]\ttraining's rmse: 0.600044\tvalid_1's rmse: 0.597768\n",
      "[16700]\ttraining's rmse: 0.599934\tvalid_1's rmse: 0.597674\n",
      "[16800]\ttraining's rmse: 0.599826\tvalid_1's rmse: 0.597579\n",
      "[16900]\ttraining's rmse: 0.59972\tvalid_1's rmse: 0.597491\n",
      "[17000]\ttraining's rmse: 0.599614\tvalid_1's rmse: 0.597399\n",
      "[17100]\ttraining's rmse: 0.59951\tvalid_1's rmse: 0.597308\n",
      "[17200]\ttraining's rmse: 0.599415\tvalid_1's rmse: 0.597227\n",
      "[17300]\ttraining's rmse: 0.59931\tvalid_1's rmse: 0.597135\n",
      "[17400]\ttraining's rmse: 0.599204\tvalid_1's rmse: 0.597044\n",
      "[17500]\ttraining's rmse: 0.599099\tvalid_1's rmse: 0.596952\n",
      "[17600]\ttraining's rmse: 0.599\tvalid_1's rmse: 0.596866\n",
      "[17700]\ttraining's rmse: 0.598902\tvalid_1's rmse: 0.59678\n",
      "[17800]\ttraining's rmse: 0.598796\tvalid_1's rmse: 0.596685\n",
      "[17900]\ttraining's rmse: 0.598699\tvalid_1's rmse: 0.596594\n",
      "[18000]\ttraining's rmse: 0.598609\tvalid_1's rmse: 0.596511\n",
      "[18100]\ttraining's rmse: 0.59852\tvalid_1's rmse: 0.596434\n",
      "[18200]\ttraining's rmse: 0.598434\tvalid_1's rmse: 0.596359\n",
      "[18300]\ttraining's rmse: 0.598353\tvalid_1's rmse: 0.59629\n",
      "[18400]\ttraining's rmse: 0.598274\tvalid_1's rmse: 0.596225\n",
      "[18500]\ttraining's rmse: 0.5982\tvalid_1's rmse: 0.596165\n",
      "[18600]\ttraining's rmse: 0.598124\tvalid_1's rmse: 0.596101\n",
      "[18700]\ttraining's rmse: 0.598052\tvalid_1's rmse: 0.596038\n",
      "[18800]\ttraining's rmse: 0.597977\tvalid_1's rmse: 0.595975\n",
      "[18900]\ttraining's rmse: 0.597907\tvalid_1's rmse: 0.595915\n",
      "[19000]\ttraining's rmse: 0.597837\tvalid_1's rmse: 0.595859\n",
      "[19100]\ttraining's rmse: 0.597767\tvalid_1's rmse: 0.595806\n",
      "[19200]\ttraining's rmse: 0.597693\tvalid_1's rmse: 0.595745\n",
      "[19300]\ttraining's rmse: 0.597623\tvalid_1's rmse: 0.595688\n",
      "[19400]\ttraining's rmse: 0.597554\tvalid_1's rmse: 0.595634\n",
      "[19500]\ttraining's rmse: 0.597489\tvalid_1's rmse: 0.595581\n",
      "[19600]\ttraining's rmse: 0.597422\tvalid_1's rmse: 0.595532\n",
      "[19700]\ttraining's rmse: 0.597361\tvalid_1's rmse: 0.595487\n",
      "[19800]\ttraining's rmse: 0.597297\tvalid_1's rmse: 0.59544\n",
      "[19900]\ttraining's rmse: 0.597233\tvalid_1's rmse: 0.595393\n",
      "[20000]\ttraining's rmse: 0.597171\tvalid_1's rmse: 0.595348\n",
      "[20100]\ttraining's rmse: 0.597109\tvalid_1's rmse: 0.595305\n",
      "[20200]\ttraining's rmse: 0.597053\tvalid_1's rmse: 0.595264\n",
      "[20300]\ttraining's rmse: 0.596995\tvalid_1's rmse: 0.59522\n",
      "[20400]\ttraining's rmse: 0.59694\tvalid_1's rmse: 0.595182\n",
      "[20500]\ttraining's rmse: 0.596885\tvalid_1's rmse: 0.595146\n",
      "[20600]\ttraining's rmse: 0.596831\tvalid_1's rmse: 0.595108\n",
      "[20700]\ttraining's rmse: 0.596774\tvalid_1's rmse: 0.595058\n",
      "[20800]\ttraining's rmse: 0.59672\tvalid_1's rmse: 0.595017\n",
      "[20900]\ttraining's rmse: 0.596665\tvalid_1's rmse: 0.594969\n",
      "[21000]\ttraining's rmse: 0.596612\tvalid_1's rmse: 0.594925\n",
      "[21100]\ttraining's rmse: 0.596566\tvalid_1's rmse: 0.594887\n",
      "[21200]\ttraining's rmse: 0.596521\tvalid_1's rmse: 0.594852\n",
      "[21300]\ttraining's rmse: 0.596475\tvalid_1's rmse: 0.594814\n",
      "[21400]\ttraining's rmse: 0.596428\tvalid_1's rmse: 0.594773\n",
      "[21500]\ttraining's rmse: 0.596377\tvalid_1's rmse: 0.594733\n",
      "[21600]\ttraining's rmse: 0.596328\tvalid_1's rmse: 0.594697\n",
      "[21700]\ttraining's rmse: 0.596276\tvalid_1's rmse: 0.594659\n",
      "[21800]\ttraining's rmse: 0.596229\tvalid_1's rmse: 0.594624\n",
      "[21900]\ttraining's rmse: 0.596187\tvalid_1's rmse: 0.594592\n",
      "[22000]\ttraining's rmse: 0.596143\tvalid_1's rmse: 0.594557\n",
      "[22100]\ttraining's rmse: 0.596094\tvalid_1's rmse: 0.594518\n",
      "[22200]\ttraining's rmse: 0.596053\tvalid_1's rmse: 0.594484\n",
      "[22300]\ttraining's rmse: 0.596012\tvalid_1's rmse: 0.594451\n",
      "[22400]\ttraining's rmse: 0.595972\tvalid_1's rmse: 0.59442\n",
      "[22500]\ttraining's rmse: 0.595931\tvalid_1's rmse: 0.594388\n",
      "[22600]\ttraining's rmse: 0.595891\tvalid_1's rmse: 0.594359\n",
      "[22700]\ttraining's rmse: 0.595852\tvalid_1's rmse: 0.594331\n",
      "[22800]\ttraining's rmse: 0.595812\tvalid_1's rmse: 0.594301\n",
      "[22900]\ttraining's rmse: 0.595776\tvalid_1's rmse: 0.594276\n",
      "[23000]\ttraining's rmse: 0.595743\tvalid_1's rmse: 0.594254\n",
      "[23100]\ttraining's rmse: 0.595707\tvalid_1's rmse: 0.594229\n",
      "[23200]\ttraining's rmse: 0.595677\tvalid_1's rmse: 0.594208\n",
      "[23300]\ttraining's rmse: 0.595645\tvalid_1's rmse: 0.594186\n",
      "[23400]\ttraining's rmse: 0.595613\tvalid_1's rmse: 0.594161\n",
      "[23500]\ttraining's rmse: 0.59558\tvalid_1's rmse: 0.594134\n",
      "[23600]\ttraining's rmse: 0.595551\tvalid_1's rmse: 0.594114\n",
      "[23700]\ttraining's rmse: 0.595523\tvalid_1's rmse: 0.594093\n",
      "[23800]\ttraining's rmse: 0.595493\tvalid_1's rmse: 0.594066\n",
      "[23900]\ttraining's rmse: 0.595465\tvalid_1's rmse: 0.594045\n",
      "[24000]\ttraining's rmse: 0.595439\tvalid_1's rmse: 0.594028\n",
      "[24100]\ttraining's rmse: 0.595411\tvalid_1's rmse: 0.594006\n",
      "[24200]\ttraining's rmse: 0.595382\tvalid_1's rmse: 0.593982\n",
      "[24300]\ttraining's rmse: 0.595352\tvalid_1's rmse: 0.593962\n",
      "[24400]\ttraining's rmse: 0.595325\tvalid_1's rmse: 0.593942\n",
      "[24500]\ttraining's rmse: 0.595298\tvalid_1's rmse: 0.593924\n",
      "[24600]\ttraining's rmse: 0.595273\tvalid_1's rmse: 0.593906\n",
      "[24700]\ttraining's rmse: 0.595247\tvalid_1's rmse: 0.593887\n",
      "[24800]\ttraining's rmse: 0.595224\tvalid_1's rmse: 0.593871\n",
      "[24900]\ttraining's rmse: 0.595199\tvalid_1's rmse: 0.593851\n",
      "[25000]\ttraining's rmse: 0.595176\tvalid_1's rmse: 0.593833\n",
      "[25100]\ttraining's rmse: 0.595153\tvalid_1's rmse: 0.593817\n",
      "[25200]\ttraining's rmse: 0.59513\tvalid_1's rmse: 0.5938\n",
      "[25300]\ttraining's rmse: 0.595109\tvalid_1's rmse: 0.593786\n",
      "[25400]\ttraining's rmse: 0.595087\tvalid_1's rmse: 0.593769\n",
      "[25500]\ttraining's rmse: 0.595064\tvalid_1's rmse: 0.593751\n",
      "[25600]\ttraining's rmse: 0.595041\tvalid_1's rmse: 0.593731\n",
      "[25700]\ttraining's rmse: 0.595019\tvalid_1's rmse: 0.593713\n",
      "[25800]\ttraining's rmse: 0.594999\tvalid_1's rmse: 0.593698\n",
      "[25900]\ttraining's rmse: 0.59498\tvalid_1's rmse: 0.593683\n",
      "[26000]\ttraining's rmse: 0.594962\tvalid_1's rmse: 0.593671\n",
      "[26100]\ttraining's rmse: 0.594943\tvalid_1's rmse: 0.593659\n",
      "[26200]\ttraining's rmse: 0.594925\tvalid_1's rmse: 0.593647\n",
      "[26300]\ttraining's rmse: 0.594907\tvalid_1's rmse: 0.593634\n",
      "[26400]\ttraining's rmse: 0.594888\tvalid_1's rmse: 0.593621\n",
      "[26500]\ttraining's rmse: 0.594871\tvalid_1's rmse: 0.593608\n",
      "[26600]\ttraining's rmse: 0.594854\tvalid_1's rmse: 0.593597\n",
      "[26700]\ttraining's rmse: 0.594839\tvalid_1's rmse: 0.593588\n",
      "[26800]\ttraining's rmse: 0.594822\tvalid_1's rmse: 0.593579\n",
      "[26900]\ttraining's rmse: 0.594807\tvalid_1's rmse: 0.59357\n",
      "[27000]\ttraining's rmse: 0.594791\tvalid_1's rmse: 0.593562\n",
      "[27100]\ttraining's rmse: 0.594776\tvalid_1's rmse: 0.593553\n",
      "[27200]\ttraining's rmse: 0.594762\tvalid_1's rmse: 0.593544\n",
      "[27300]\ttraining's rmse: 0.594746\tvalid_1's rmse: 0.593535\n",
      "[27400]\ttraining's rmse: 0.594729\tvalid_1's rmse: 0.593524\n",
      "[27500]\ttraining's rmse: 0.594716\tvalid_1's rmse: 0.593515\n",
      "[27600]\ttraining's rmse: 0.594701\tvalid_1's rmse: 0.593504\n",
      "[27700]\ttraining's rmse: 0.594686\tvalid_1's rmse: 0.593498\n",
      "[27800]\ttraining's rmse: 0.594673\tvalid_1's rmse: 0.593494\n",
      "[27900]\ttraining's rmse: 0.594659\tvalid_1's rmse: 0.593488\n",
      "[28000]\ttraining's rmse: 0.594644\tvalid_1's rmse: 0.593479\n",
      "[28100]\ttraining's rmse: 0.594629\tvalid_1's rmse: 0.593471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28200]\ttraining's rmse: 0.594617\tvalid_1's rmse: 0.593466\n",
      "[28300]\ttraining's rmse: 0.594604\tvalid_1's rmse: 0.59346\n",
      "[28400]\ttraining's rmse: 0.59459\tvalid_1's rmse: 0.593455\n",
      "[28500]\ttraining's rmse: 0.594579\tvalid_1's rmse: 0.59345\n",
      "[28600]\ttraining's rmse: 0.594568\tvalid_1's rmse: 0.593443\n",
      "[28700]\ttraining's rmse: 0.594555\tvalid_1's rmse: 0.593434\n",
      "[28800]\ttraining's rmse: 0.594541\tvalid_1's rmse: 0.593427\n",
      "[28900]\ttraining's rmse: 0.594528\tvalid_1's rmse: 0.593422\n",
      "[29000]\ttraining's rmse: 0.594515\tvalid_1's rmse: 0.593414\n",
      "[29100]\ttraining's rmse: 0.594502\tvalid_1's rmse: 0.593409\n",
      "[29200]\ttraining's rmse: 0.594491\tvalid_1's rmse: 0.593405\n",
      "[29300]\ttraining's rmse: 0.59448\tvalid_1's rmse: 0.593399\n",
      "[29400]\ttraining's rmse: 0.594468\tvalid_1's rmse: 0.593391\n",
      "[29500]\ttraining's rmse: 0.594456\tvalid_1's rmse: 0.593383\n",
      "[29600]\ttraining's rmse: 0.594444\tvalid_1's rmse: 0.593373\n",
      "[29700]\ttraining's rmse: 0.594432\tvalid_1's rmse: 0.593364\n",
      "[29800]\ttraining's rmse: 0.594421\tvalid_1's rmse: 0.593358\n",
      "[29900]\ttraining's rmse: 0.594411\tvalid_1's rmse: 0.593352\n",
      "[30000]\ttraining's rmse: 0.594401\tvalid_1's rmse: 0.593346\n",
      "[30100]\ttraining's rmse: 0.594391\tvalid_1's rmse: 0.59334\n",
      "[30200]\ttraining's rmse: 0.594381\tvalid_1's rmse: 0.593335\n",
      "[30300]\ttraining's rmse: 0.594372\tvalid_1's rmse: 0.59333\n",
      "[30400]\ttraining's rmse: 0.594363\tvalid_1's rmse: 0.593325\n",
      "[30500]\ttraining's rmse: 0.594354\tvalid_1's rmse: 0.593321\n",
      "[30600]\ttraining's rmse: 0.594345\tvalid_1's rmse: 0.593316\n",
      "[30700]\ttraining's rmse: 0.594336\tvalid_1's rmse: 0.593311\n",
      "[30800]\ttraining's rmse: 0.594327\tvalid_1's rmse: 0.593305\n",
      "[30900]\ttraining's rmse: 0.594319\tvalid_1's rmse: 0.593301\n",
      "[31000]\ttraining's rmse: 0.59431\tvalid_1's rmse: 0.593297\n",
      "[31100]\ttraining's rmse: 0.594302\tvalid_1's rmse: 0.593294\n",
      "[31200]\ttraining's rmse: 0.594294\tvalid_1's rmse: 0.59329\n",
      "[31300]\ttraining's rmse: 0.594285\tvalid_1's rmse: 0.593283\n",
      "[31400]\ttraining's rmse: 0.594276\tvalid_1's rmse: 0.593277\n",
      "[31500]\ttraining's rmse: 0.594268\tvalid_1's rmse: 0.593272\n",
      "[31600]\ttraining's rmse: 0.594261\tvalid_1's rmse: 0.593268\n",
      "[31700]\ttraining's rmse: 0.594254\tvalid_1's rmse: 0.593264\n",
      "[31800]\ttraining's rmse: 0.594246\tvalid_1's rmse: 0.59326\n",
      "[31900]\ttraining's rmse: 0.594238\tvalid_1's rmse: 0.593257\n",
      "[32000]\ttraining's rmse: 0.594231\tvalid_1's rmse: 0.593255\n",
      "[32100]\ttraining's rmse: 0.594224\tvalid_1's rmse: 0.593251\n",
      "[32200]\ttraining's rmse: 0.594217\tvalid_1's rmse: 0.593247\n",
      "[32300]\ttraining's rmse: 0.594211\tvalid_1's rmse: 0.593244\n",
      "[32400]\ttraining's rmse: 0.594205\tvalid_1's rmse: 0.593242\n",
      "[32500]\ttraining's rmse: 0.594198\tvalid_1's rmse: 0.593239\n",
      "[32600]\ttraining's rmse: 0.594191\tvalid_1's rmse: 0.593238\n",
      "[32700]\ttraining's rmse: 0.594183\tvalid_1's rmse: 0.593236\n",
      "[32800]\ttraining's rmse: 0.594177\tvalid_1's rmse: 0.593235\n",
      "[32900]\ttraining's rmse: 0.594171\tvalid_1's rmse: 0.593234\n",
      "[33000]\ttraining's rmse: 0.594164\tvalid_1's rmse: 0.593233\n",
      "[33100]\ttraining's rmse: 0.594158\tvalid_1's rmse: 0.593232\n",
      "[33200]\ttraining's rmse: 0.594153\tvalid_1's rmse: 0.593231\n",
      "[33300]\ttraining's rmse: 0.594146\tvalid_1's rmse: 0.593227\n",
      "[33400]\ttraining's rmse: 0.59414\tvalid_1's rmse: 0.593225\n",
      "[33500]\ttraining's rmse: 0.594134\tvalid_1's rmse: 0.593223\n",
      "[33600]\ttraining's rmse: 0.594128\tvalid_1's rmse: 0.59322\n",
      "[33700]\ttraining's rmse: 0.594123\tvalid_1's rmse: 0.593219\n",
      "[33800]\ttraining's rmse: 0.594117\tvalid_1's rmse: 0.593218\n",
      "[33900]\ttraining's rmse: 0.594112\tvalid_1's rmse: 0.593217\n",
      "[34000]\ttraining's rmse: 0.594106\tvalid_1's rmse: 0.593216\n",
      "[34100]\ttraining's rmse: 0.594101\tvalid_1's rmse: 0.593215\n",
      "[34200]\ttraining's rmse: 0.594095\tvalid_1's rmse: 0.593215\n",
      "[34300]\ttraining's rmse: 0.59409\tvalid_1's rmse: 0.593214\n",
      "[34400]\ttraining's rmse: 0.594084\tvalid_1's rmse: 0.593214\n",
      "[34500]\ttraining's rmse: 0.594079\tvalid_1's rmse: 0.593214\n",
      "[34600]\ttraining's rmse: 0.594073\tvalid_1's rmse: 0.593214\n",
      "[34700]\ttraining's rmse: 0.594068\tvalid_1's rmse: 0.593215\n",
      "[34800]\ttraining's rmse: 0.594064\tvalid_1's rmse: 0.593215\n",
      "[34900]\ttraining's rmse: 0.594059\tvalid_1's rmse: 0.593216\n",
      "[35000]\ttraining's rmse: 0.594055\tvalid_1's rmse: 0.593216\n",
      "[35100]\ttraining's rmse: 0.594051\tvalid_1's rmse: 0.593216\n",
      "[35200]\ttraining's rmse: 0.594047\tvalid_1's rmse: 0.593215\n",
      "[35300]\ttraining's rmse: 0.594042\tvalid_1's rmse: 0.593213\n",
      "[35400]\ttraining's rmse: 0.594038\tvalid_1's rmse: 0.593212\n",
      "[35500]\ttraining's rmse: 0.594033\tvalid_1's rmse: 0.593212\n",
      "[35600]\ttraining's rmse: 0.594029\tvalid_1's rmse: 0.593212\n",
      "[35700]\ttraining's rmse: 0.594025\tvalid_1's rmse: 0.593212\n",
      "[35800]\ttraining's rmse: 0.59402\tvalid_1's rmse: 0.593212\n",
      "[35900]\ttraining's rmse: 0.594016\tvalid_1's rmse: 0.593212\n",
      "[36000]\ttraining's rmse: 0.594012\tvalid_1's rmse: 0.593211\n",
      "[36100]\ttraining's rmse: 0.594007\tvalid_1's rmse: 0.593211\n",
      "[36200]\ttraining's rmse: 0.594004\tvalid_1's rmse: 0.593212\n",
      "[36300]\ttraining's rmse: 0.594\tvalid_1's rmse: 0.593211\n",
      "[36400]\ttraining's rmse: 0.593996\tvalid_1's rmse: 0.593212\n",
      "[36500]\ttraining's rmse: 0.593992\tvalid_1's rmse: 0.593212\n",
      "[36600]\ttraining's rmse: 0.593989\tvalid_1's rmse: 0.593213\n",
      "[36700]\ttraining's rmse: 0.593986\tvalid_1's rmse: 0.593214\n",
      "[36800]\ttraining's rmse: 0.593982\tvalid_1's rmse: 0.593215\n",
      "[36900]\ttraining's rmse: 0.593979\tvalid_1's rmse: 0.593214\n",
      "[37000]\ttraining's rmse: 0.593975\tvalid_1's rmse: 0.593211\n",
      "Model trained. Predicting...\n",
      "Prediction complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training LGBM model with cross-validation...\")\n",
    "params = {\n",
    "    \"application\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"num_leaves\": 32,\n",
    "    \"min_sum_hessian_in_leaf\": 1e-2,\n",
    "    \"min_gain_to_split\": 0,\n",
    "    \n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"feature_fraction\": 0.8,\n",
    "    \"num_threads\": 4,\n",
    "    \"metric\": \"rmse\"\n",
    "}\n",
    "\n",
    "d_train = lgb.Dataset(X_train, y_train)\n",
    "d_valid = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "watchlist = [d_train, d_valid]\n",
    "\n",
    "# default value of folds: 5\n",
    "lgb_model1 = lgb.train(params, train_set=d_train, num_boost_round=37000, valid_sets=watchlist, verbose_eval=1000)\n",
    "\n",
    "print(\"Model trained. Predicting...\")\n",
    "\n",
    "test_probs = lgb_model1.predict(test)\n",
    "test_probs = np.expm1(test_probs)\n",
    "\n",
    "result = pd.DataFrame({\"id\": index_test, \"visitors\": test_probs})\n",
    "result.to_csv(\"LGB_sub.csv\", index=False) # 0.60\n",
    "print(\"Prediction complete.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
